{
  "name": "Merkezi_Komuta_Konsolu_AI_Gateway",
  "nodes": [
    {
      "id": "webhook_receiver",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [250, 300],
      "parameters": {
        "path": "ai-gateway",
        "responseMode": "responseNode",
        "options": {
          "responseContentType": "application/json",
          "responsePropertyName": "data",
          "responseHeaders": {
            "values": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              }
            ]
          }
        }
      }
    },
    {
      "id": "request_validator",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [450, 300],
      "parameters": {
        "functionCode": "// Request Validation and Enrichment\nconst body = $input.first().json;\nconst errors = [];\n\n// Required field validation\nif (!body.model) errors.push('Model field is required');\nif (!body.prompt) errors.push('Prompt field is required');\n\n// Model whitelist\nconst allowedModels = [\n  // Claude Models\n  'claude-3-opus-20240229',\n  'claude-3-sonnet',\n  'claude-3-sonnet-20240229',\n  'claude-3-haiku-20240307',\n  'claude-3-5-sonnet-20241022',\n  // GPT Models\n 'gpt-4-turbo-preview',\n  'gpt-4',\n  'gpt-3.5-turbo',\n  'gpt-4o',\n  'gpt-4o-mini',\n  // Gemini Models\n  'gemini-pro',\n  'gemini-pro-vision'\n];\n\nif (body.model && !allowedModels.includes(body.model)) {\n  errors.push(`Invalid model: ${body.model}`);\n}\n\n// Return error if validation fails\nif (errors.length > 0) {\n  return {\n    json: {\n      success: false,\n      errors: errors,\n      timestamp: new Date().toISOString()\n    }\n  };\n}\n\n// Enrich request with metadata\nreturn {\n  json: {\n    ...body,\n    requestId: crypto.randomUUID(),\n    timestamp: new Date().toISOString(),\n    provider: body.model.startsWith('claude') ? 'anthropic' : \n              body.model.startsWith('gpt') ? 'openai' : \n              body.model.startsWith('gemini') ? 'google' : 'unknown'\n  }\n};"
      }
    },
    {
      "id": "router",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 1,
      "position": [650, 300],
      "parameters": {
        "dataType": "string",
        "value1": "={{ $json.provider }}",
        "rules": {
          "rules": [
            {
              "value2": "anthropic",
              "output": 0
            },
            {
              "value2": "openai",
              "output": 1
            },
            {
              "value2": "google",
              "output": 2
            }
          ]
        },
        "fallbackOutput": 3
      }
    },
    {
      "id": "anthropic_handler",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [850, 100],
      "parameters": {
        "functionCode": "// Anthropic Claude API Handler\nconst data = $input.first().json;\n\n// Format conversation for Claude API\nconst messages = [];\n\nif (data.conversation_history && data.conversation_history.length > 0) {\n  messages.push(...data.conversation_history);\n}\n\nmessages.push({\n  role: 'user',\n  content: data.prompt\n});\n\n// Prepare API request\nreturn {\n  json: {\n    requestId: data.requestId,\n    provider: 'anthropic',\n    model: data.model,\n    messages: messages,\n    max_tokens: data.max_tokens || 4096,\n    temperature: data.temperature || 0.7,\n    apiEndpoint: 'https://api.anthropic.com/v1/messages',\n    headers: {\n      'x-api-key': '{{ $credentials.anthropicApi.apiKey }}',\n      'anthropic-version': '2023-06-01',\n      'content-type': 'application/json'\n    }\n  }\n};"
      }
    },
    {
      "id": "openai_handler",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [850, 300],
      "parameters": {
        "functionCode": "// OpenAI GPT API Handler\nconst data = $input.first().json;\n\n// Format conversation for OpenAI API\nconst messages = [];\n\nif (data.conversation_history && data.conversation_history.length > 0) {\n  messages.push(...data.conversation_history);\n}\n\nmessages.push({\n  role: 'user',\n  content: data.prompt\n});\n\n// Prepare API request\nreturn {\n  json: {\n    requestId: data.requestId,\n    provider: 'openai',\n    model: data.model,\n    messages: messages,\n    max_tokens: data.max_tokens || 4096,\n    temperature: data.temperature || 0.7,\n    apiEndpoint: 'https://api.openai.com/v1/chat/completions',\n    headers: {\n      'Authorization': 'Bearer {{ $credentials.openaiApi.apiKey }}',\n      'Content-Type': 'application/json'\n    }\n  }\n};"
      }
    },
    {
      "id": "google_handler",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [850, 500],
      "parameters": {
        "functionCode": "// Google Gemini API Handler\nconst data = $input.first().json;\n\n// Format conversation for Gemini API\nconst contents = [];\n\nif (data.conversation_history && data.conversation_history.length > 0) {\n  data.conversation_history.forEach(msg => {\n    contents.push({\n      role: msg.role === 'assistant' ? 'model' : 'user',\n      parts: [{ text: msg.content }]\n    });\n  });\n}\n\ncontents.push({\n  role: 'user',\n  parts: [{ text: data.prompt }]\n});\n\n// Prepare API request\nreturn {\n  json: {\n    requestId: data.requestId,\n    provider: 'google',\n    model: data.model,\n    contents: contents,\n    generationConfig: {\n      maxOutputTokens: data.max_tokens || 4096,\n      temperature: data.temperature || 0.7\n    },\n    apiEndpoint: `https://generativelanguage.googleapis.com/v1beta/models/${data.model}:generateContent`,\n    headers: {\n      'x-goog-api-key': '{{ $credentials.googleApi.apiKey }}',\n      'Content-Type': 'application/json'\n    }\n  }\n};"
      }
    },
    {
      "id": "http_request",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 3,
      "position": [1050, 300],
      "parameters": {
        "method": "POST",
        "url": "={{ $json.apiEndpoint }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": "={{ $json.headers }}"
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": "={{ $json.provider === 'anthropic' ? {model: $json.model, messages: $json.messages, max_tokens: $json.max_tokens} : $json.provider === 'openai' ? {model: $json.model, messages: $json.messages, max_tokens: $json.max_tokens, temperature: $json.temperature} : {contents: $json.contents, generationConfig: $json.generationConfig} }}"
        },
        "options": {
          "timeout": 30000,
          "response": {
            "response": {
              "fullResponse": true
            }
          }
        }
      }
    },
    {
      "id": "response_normalizer",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1250, 300],
      "parameters": {
        "functionCode": "// Normalize responses from different providers\nconst input = $input.first().json;\nconst response = input.body;\nconst provider = input.provider || 'unknown';\n\nlet normalizedResponse = {\n  success: true,\n  requestId: input.requestId,\n  provider: provider,\n  model: input.model,\n  timestamp: new Date().toISOString(),\n  usage: {},\n  content: '',\n  raw_response: response\n};\n\ntry {\n  if (provider === 'anthropic') {\n    normalizedResponse.content = response.content[0].text;\n    normalizedResponse.usage = {\n      input_tokens: response.usage.input_tokens,\n      output_tokens: response.usage.output_tokens,\n      total_tokens: response.usage.input_tokens + response.usage.output_tokens\n    };\n    normalizedResponse.stop_reason = response.stop_reason;\n  } \n  else if (provider === 'openai') {\n    normalizedResponse.content = response.choices[0].message.content;\n    normalizedResponse.usage = {\n      input_tokens: response.usage.prompt_tokens,\n      output_tokens: response.usage.completion_tokens,\n      total_tokens: response.usage.total_tokens\n    };\n    normalizedResponse.finish_reason = response.choices[0].finish_reason;\n  } \n  else if (provider === 'google') {\n    normalizedResponse.content = response.candidates[0].content.parts[0].text;\n    normalizedResponse.usage = {\n      input_tokens: response.usageMetadata?.promptTokenCount || 0,\n      output_tokens: response.usageMetadata?.candidatesTokenCount || 0,\n      total_tokens: (response.usageMetadata?.promptTokenCount || 0) + (response.usageMetadata?.candidatesTokenCount || 0)\n    };\n    normalizedResponse.finish_reason = response.candidates[0].finishReason;\n  }\n} catch (error) {\n  normalizedResponse.success = false;\n  normalizedResponse.error = `Failed to parse response: ${error.message}`;\n}\n\nreturn { json: normalizedResponse };"
      }
    },
    {
      "id": "error_handler",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1050, 500],
      "parameters": {
        "functionCode": "// Centralized Error Handler\nconst error = $input.first().json;\n\nconst errorResponse = {\n  success: false,\n  requestId: error.requestId || 'unknown',\n  timestamp: new Date().toISOString(),\n  error: {\n    message: error.message || 'An unexpected error occurred',\n    code: error.code || 'INTERNAL_ERROR',\n    details: error.details || {},\n    provider: error.provider || 'unknown'\n  }\n};\n\n// Log error for monitoring\nconsole.error('API Error:', JSON.stringify(errorResponse, null, 2));\n\nreturn { json: errorResponse };"
      }
    },
    {
      "id": "response_logger",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1450, 300],
      "parameters": {
        "functionCode": "// Log successful responses for analytics\nconst response = $input.first().json;\n\n// Here you can add logging to external services\n// Example: Send to Elasticsearch, CloudWatch, etc.\nconst logEntry = {\n  timestamp: response.timestamp,\n  requestId: response.requestId,\n  provider: response.provider,\n  model: response.model,\n  success: response.success,\n  tokenUsage: response.usage,\n  responseTime: Date.now() - new Date(response.timestamp).getTime()\n};\n\n// For now, just console log\nconsole.log('API Log:', JSON.stringify(logEntry, null, 2));\n\n// Pass through the response\nreturn { json: response };"
      }
    },
    {
      "id": "webhook_response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1650, 300],
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {
          "responseCode": "={{ $json.success ? 200 : 400 }}"
        }
      }
    }
  ],
  "connections": {
    "webhook_receiver": {
      "main": [
        [
          {
            "node": "request_validator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "request_validator": {
      "main": [
        [
          {
            "node": "router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "router": {
      "main": [
        [
          {
            "node": "anthropic_handler",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "openai_handler",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "google_handler",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "error_handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "anthropic_handler": {
      "main": [
        [
          {
            "node": "http_request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "openai_handler": {
      "main": [
        [
          {
            "node": "http_request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "google_handler": {
      "main": [
        [
          {
            "node": "http_request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "http_request": {
      "main": [
        [
          {
            "node": "response_normalizer",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "error_handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "response_normalizer": {
      "main": [
        [
          {
            "node": "response_logger",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "error_handler": {
      "main": [
        [
          {
            "node": "webhook_response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "response_logger": {
      "main": [
        [
          {
            "node": "webhook_response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "saveManualExecutions": true,
    "callerPolicy": "workflowsFromSameOwner",
    "errorWorkflow": "error_notification_workflow"
  },
  "staticData": null,
  "pinData": {},
  "versionId": "1.0.0",
  "triggerCount": 1,
  "tags": [
    {
      "name": "AI Gateway",
      "createdAt": "2024-01-01T00:00:00.000Z"
    },
    {
      "name": "Production",
      "createdAt": "2024-01-01T00:00:00.000Z"
    }
  ]
}